# üß† Reconhecimento de Entidades Nomeadas com LLM (NER em Portugu√™s)

Este projeto apresenta o fine-tuning de um modelo BERT para a tarefa de **Reconhecimento de Entidades Nomeadas (Named Entity Recognition - NER)** em textos em l√≠ngua portuguesa, utilizando a arquitetura `neuralmind/bert-base-portuguese-cased`.

---

## üìò Introdu√ß√£o

O **Reconhecimento de Entidades Nomeadas (NER)** √© uma das tarefas mais fundamentais do **Processamento de Linguagem Natural (PLN)**. Seu objetivo √© **identificar automaticamente nomes de pessoas, locais, organiza√ß√µes, datas, leis e outros elementos sem√¢nticos importantes** em um texto. Essa tarefa √© essencial para transformar texto bruto em dados estruturados utiliz√°veis por aplica√ß√µes como:

- An√°lise de contratos e decis√µes jur√≠dicas;
- Extra√ß√£o de informa√ß√µes em not√≠cias;
- Indexa√ß√£o de conte√∫do acad√™mico;
- Apoio a sistemas de recomenda√ß√£o e mecanismos de busca.

Com a evolu√ß√£o dos **Modelos de Linguagem de Grande Escala (LLMs)** como BERT, tornou-se poss√≠vel treinar modelos altamente precisos para tarefas de NER, inclusive em idiomas com menos recursos, como o portugu√™s.

---

## üß∞ Tecnologias Utilizadas

- **Python 3.10**
- **Hugging Face Transformers**
- **Hugging Face Datasets**
- **Pandas / NumPy / Scikit-learn**
- **Matplotlib / Seaborn**
- **Token Classification com `AutoModelForTokenClassification`**
- Modelo base: `neuralmind/bert-base-portuguese-cased`

---

## üìÇ Dataset Utilizado ‚Äî leNER-Br

- **Fonte**: [leNER-Br](https://github.com/Orochimarufan/LeNER-Br)
- **Formato**: CoNLL 2003 (cada linha cont√©m um token e seu r√≥tulo)
- **Idioma**: Portugu√™s
- **Tipo de entidades rotuladas**:
  - `PESSOA`
  - `LOCAL`
  - `ORGANIZACAO`
  - `JURISPRUDENCIA`
  - `LEGISLACAO`
  - `TEMPO`
- **Total de senten√ßas utilizadas**: 1.176

Exemplo de r√≥tulos no dataset:


---

## üîÑ Pr√©-processamento

As principais etapas do pr√©-processamento inclu√≠ram:

1. **Leitura e agrupamento das senten√ßas** com tokens e r√≥tulos;
2. Convers√£o dos dados para estrutura de lista de dicion√°rios `{tokens: [...], ner_tags: [...]}`;
3. Mapeamento dos r√≥tulos para √≠ndices num√©ricos;
4. Tokeniza√ß√£o usando o tokenizer do `neuralmind/bert-base-portuguese-cased`;
5. Alinhamento dos r√≥tulos com sub-palavras (tokens gerados pelo BERT), com m√°scara `-100` para ignorar sub-tokens n√£o iniciais durante o treinamento.

---

## üß† Treinamento do Modelo

Utilizamos o modelo `AutoModelForTokenClassification` da Hugging Face para realizar o fine-tuning em 10 √©pocas.

### Hiperpar√¢metros principais:

- **Modelo base**: `neuralmind/bert-base-portuguese-cased`
- **√âpocas**: 10  
- **Batch size**: 16  
- **Otimiza√ß√£o**: AdamW  
- **Fun√ß√£o de perda**: CrossEntropyLoss (com `-100` ignorado)

---

## üìà Avalia√ß√£o do Desempenho

As seguintes m√©tricas foram coletadas durante o treinamento:

| √âpoca | Precis√£o | Recall | F1-Score | Acur√°cia |
|-------|----------|--------|----------|----------|
| 1     | 0.548    | 0.547  | 0.547    | 92.78%   |
| 5     | 0.881    | 0.903  | 0.892    | 98.39%   |
| 9     | **0.893**| **0.912**| **0.903**| **98.59%** |
| 10    | 0.882    | 0.909  | 0.895    | 98.53%   |

---

## üìä Gr√°ficos de Desempenho

### F1-Score por √©poca
![alt text](<IMAGENS/GRAFICO F1.png>)

O gr√°fico mostra crescimento r√°pido nas primeiras √©pocas e estabiliza√ß√£o por volta da √©poca 5. Isso indica **converg√™ncia do modelo**, sem overfitting.

### Precis√£o vs Recall
![alt text](<IMAGENS/Captura de tela 2025-06-27 232506.png>)

As curvas mostram proximidade e estabilidade entre precis√£o e recall, sugerindo que o modelo mant√©m um **equil√≠brio entre identificar entidades corretamente e n√£o rotular excessivamente**.

---

## üß™ Exemplo de Uso e Sa√≠da do Modelo

### Entrada:

"Em 18 de julho de 2023, a advogada Ana Paula Resende da Ordem dos Advogados do Brasil, localizada em Curitiba, argumentou com base no Artigo 14 da Constitui√ß√£o Federal e citou o Recurso Especial 123.456/SP, refor√ßando seu ponto."

### Sa√≠da (entidades identificadas):

![alt text](<IMAGENS/SA√çDA MODELO.png>)


O modelo √© capaz de reconhecer nomes pr√≥prios, locais e datas dentro de um contexto jur√≠dico ou noticioso com excelente precis√£o.

---

## ‚úÖ Conclus√£o

O desenvolvimento deste projeto demonstrou, na pr√°tica, o potencial dos **modelos de linguagem baseados em Transformers** ‚Äî como o BERT ‚Äî na tarefa de **Reconhecimento de Entidades Nomeadas (NER)** em l√≠ngua portuguesa. A escolha do modelo `neuralmind/bert-base-portuguese-cased`, treinado especificamente com dados do portugu√™s, aliada a uma pipeline bem estruturada de pr√©-processamento, tokeniza√ß√£o e alinhamento de r√≥tulos, possibilitou um desempenho s√≥lido e est√°vel ao longo das √©pocas.

As m√©tricas obtidas ‚Äî com destaque para um **F1-Score superior a 90%** e **acur√°cia acima de 98%** ‚Äî indicam que o modelo treinado √© capaz de **identificar entidades com alta precis√£o e equil√≠brio**, mesmo em senten√ßas complexas. Isso valida seu uso em **cen√°rios reais**, como automa√ß√£o de an√°lise jur√≠dica, indexa√ß√£o de documentos, extra√ß√£o de informa√ß√µes em grandes volumes de texto e suporte a sistemas inteligentes de busca.

Al√©m dos resultados num√©ricos, o projeto tamb√©m refor√ßa a import√¢ncia de se desenvolver e adaptar tecnologias de PLN para o portugu√™s, ampliando o acesso e a aplicabilidade dessas solu√ß√µes em contextos nacionais.

Por fim, este trabalho serve como **base s√≥lida para estudos futuros**, como:

- Expans√£o do n√∫mero de classes de entidades;
- Uso de arquiteturas mais recentes (como RoBERTa ou LLaMA);
- Integra√ß√£o com aplica√ß√µes em tempo real via APIs;
- Transfer√™ncia para dom√≠nios espec√≠ficos (jur√≠dico, biom√©dico, jornal√≠stico).

